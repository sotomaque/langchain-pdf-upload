{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 22 document(s) in your data.\n",
      "There are 3978 characters in your document\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_path = \"../data/paper.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "data = loader.load_and_split()  # already does the splitting\n",
    "print(f'You have {len(data)} document(s) in your data.')\n",
    "print(f'There are {len(data[0].page_content)} characters in your document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in the environment variables. Check your .env file and make sure the variable name matches.\")\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n",
      "No embedding_function provided, using default embedding function: SentenceTransformerEmbeddingFunction\n",
      "Using embedded DuckDB with persistence: data will be stored in: .\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "vectoredb = Chroma().from_documents(\n",
    "    data,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\".\"\n",
    "  )\n",
    "vectoredb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain/chains/conversational_retrieval/base.py:212: UserWarning: `ChatVectorDBChain` is deprecated - please use `from langchain.chains import ConversationalRetrievalChain`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ChatVectorDBChain\n",
    "\n",
    "qa = ChatVectorDBChain.from_llm(OpenAI(temperature=0), vectoredb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "query = \"What is the paper about? What are the most salient quotes? What are its biggest weaknesses? What, if any, assumptions are made by the paper?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This paper is about pre-training a model to detect mistakes in videos. The most salient quotes are \"To address this, we pre-train our model with a masked modeling objective that encourages the step representations to capture the global context of the entire video\" and \"Since our model learns step representations “globally” from the whole video, it is able to capture these subtle differences.\" The biggest weaknesses of the paper are that it lacks a benchmark for detecting mistakes in videos and that it makes assumptions about the relationship between different steps in the same task. The paper makes the assumption that the way a step is situated in an overall task may contain important information about the step.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"answer\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
